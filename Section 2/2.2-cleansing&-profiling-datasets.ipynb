{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c4ed23-3b81-48e0-a81c-c0028c5cf8a7",
   "metadata": {},
   "source": [
    "# 2.2 - Identify common reasons for cleansing and profiling datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6f77f-4636-4966-a5a9-445d7b70a52b",
   "metadata": {},
   "source": [
    "## Duplicate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8cb74-1fe9-4635-9e05-e89aa28166cd",
   "metadata": {},
   "source": [
    "Duplicate data is defined as either values or columns that are repeated in our data set. \n",
    "\n",
    "- After confirming that said data is infact duplicated; this issue can be eaisly resolved by removing the duplicated data until only one value or column is present. \n",
    "\n",
    "### Duplicated Values\n",
    "\n",
    "| ID | Name | Class | Grade |\n",
    "| -- | ---- | ----- | ----- | \n",
    "| 01 | Mike | History | 95 |\n",
    "| 02 | Jill | Math | 85 |\n",
    "| 01 | Mike | History | 95 |\n",
    "\n",
    "In the above table, the third entry is clearly a duplicate of the first entry. So, we can simply remove our third entry to avoid duplicate data in our data base.\n",
    "\n",
    "| ID | Name | Class | Grade |\n",
    "| -- | ---- | ----- | ----- | \n",
    "| 01 | Mike | History | 95 |\n",
    "| 02 | Jill | Math | 85 |\n",
    "\n",
    "### Duplicated Columns\n",
    "\n",
    "| ID | Name | Class | Grade | ID |\n",
    "| -- | ---- | ----- | ----- | -- |\n",
    "| 01 | Mike | History | 95 | 01 |\n",
    "| 02 | Jill | Math | 85 | 01 |\n",
    "\n",
    "Here we can see that the column 'ID' is duplicated in this table, again this can simply be removed from our database to resolve this issue. Keep in mind that a duplicated column may no always have the same heading for instance - \n",
    "\n",
    "| ID | Name | Class | Grade | StudentID |\n",
    "| -- | ---- | ----- | ----- | -- |\n",
    "| 01 | Mike | History | 95 | 01 |\n",
    "| 02 | Jill | Math | 85 | 01 |\n",
    "\n",
    "We can see that while the column name may be different, our values in the column are the same and representing the same thing, we can choose the column name that works best for our dataset and remove the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59530069-8635-4ba6-af46-9df3f7eba1cb",
   "metadata": {},
   "source": [
    "## Redundant Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d0b26-70ec-4179-a6b6-cbc304929a4b",
   "metadata": {},
   "source": [
    "Redundent data is defined as reciving more data than was requested for our task. While this will require some cleaning, it is almost never a bad thing to have more data than we need. Take for example looking at the price of BTC through the day, maybe we are looking to see the value of BTC at the top of every hour and we are given the value for every min. We can simply choose wether we want to know the value at the top of the hour or the end of the hour and remove the rest of the data. \n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | 103 |\n",
    "| 12:03 | 100 |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "| 12:59 | 101 |\n",
    "| 01:00 | 100 |\n",
    "| 01:01 | 101 |\n",
    "| 01:02 | 103 |\n",
    "| 01:03 | 100 |\n",
    "| 01:04 | 100 |\n",
    "| etc. |  |\n",
    "| 01:59 | 101 |\n",
    "\n",
    "Lets say the for this data set we have choosen to take the value of BTC at the top of the hour, this makes all the other entries redundent and the can be removed from our data base, giving us a clean database with the values that we need. \n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 01:00 | 100 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8a25d-dbf9-4162-afa3-6d659869431e",
   "metadata": {},
   "source": [
    "## Missing Values, Invalid Data and Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552a7e4-3ee6-4d23-9703-8b279dd86ab3",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Missing values in our data can be quite the issue, and depending out the type of data that we are analyzing, solving this issue can be quite complex. \n",
    "\n",
    "If it is applicable to our data we can use some valuiable methods to fill our missing data.\n",
    "- Mean\n",
    "    - the average of the numbers: a calculated \"central\" value of a set of numbers\n",
    "- Meadian\n",
    "    - the \"middle\" of a sorted list of numbers\n",
    "- Mode\n",
    "    - the most frequent number—-that is, the number that occurs the highest number of times.\n",
    "- LOCF (last object carried forward) & NOCB (next object carried back)\n",
    "    - the process of carriing either the last or next object into our missing value\n",
    "- Linear interpolation (machine learning)\n",
    "    - using other data values to calculate the missing value\n",
    "- K neareast neighbors\n",
    "    - using the similar neighbors to inffer what the missing value likely is. \n",
    "    \n",
    "Do keep in mind that it may not always be a good idea to inffer what our missing data is, think back on our example of a database of grades. \n",
    "\n",
    "| ID | Name | Class | Grade |\n",
    "| -- | ---- | ----- | ----- | \n",
    "| 01 | Mike | History | 95 |\n",
    "| 02 | Jill | Math | 85 |\n",
    "| 03 |  | Gym | 88 |\n",
    "| 01 | Mike | Math |  |\n",
    "\n",
    "In this database it would make no sense to fill our missing values using any of the above methods, as there is no way to guess what a students name is or what their grade might be. In an instance like this, we will need to reach back out to our data provider and have them provide us with the correct data that we require. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9dd38b-c977-418f-ad5e-0c394820bb0e",
   "metadata": {},
   "source": [
    "#### LOCF & NOCB\n",
    "\n",
    "Lets look again at our example of tracking the value of BTC through the day. \n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | 103 |\n",
    "| 12:03 |  |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | 103 |\n",
    "| 12:03 | 103 |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "\n",
    "Here it might make sense to use LOCF or NOCB depending on what we are doing, as filling the missing values with the next minutes or the last minutes value will still give us a good idea of how the value of BTC is fluctuating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e247f-28f0-49fb-acb5-33ccde9460f9",
   "metadata": {},
   "source": [
    "#### Linear interpolation\n",
    "\n",
    "A method useful for curve fitting using linear polynomials. It helps in building new data points within the range of a discrete set of already known data points. Therefore, the Linear interpolation is the simplest method for estimating a channel from the vector of the given channel’s estimates. It is very useful for data prediction, data forecasting, market research, and many other mathematical and scientific applications.\n",
    "\n",
    "INTERPOLATION FORMULA: $ y_1 + {(x-x_1)(y_2-y_1) \\over {x_2-x_1}} $\n",
    "\n",
    " - $ x_1 $ and $ y_1 $ are the first coordinates\n",
    " - $ x_2 $ and $ y_2 $ are the second coordinates\n",
    " - $ x $ is the point to perform the interpolation\n",
    " - $ y $ is the interpolated value\n",
    "\n",
    "Consider the folling table - \n",
    "\n",
    "| Day | Height |\n",
    "| --- | ------ |\n",
    "| 1 | 0 |\n",
    "| 3 | 4 |\n",
    "| 5 | 8 |\n",
    "| 7 | 12 |\n",
    "| 9 | 16 | \n",
    "\n",
    "Now say we wanted to know the height of the plant of the 4th day of growing. This is an example of linear growth and hence the linear interpolation formula is very much suitable here. We may take (3,4) as the first data point and (5,8) as the second data point.\n",
    "\n",
    "Our values would be as follows;\n",
    "\n",
    "- $ y_1 = 4 $\n",
    "- $ x_1 = 3 $\n",
    "- $ y_2 = 8 $\n",
    "- $ x_2 = 5 $\n",
    "\n",
    "Now we apply our formula:\n",
    "\n",
    "$ y = 4 + {(x-3)(8-5) \\over {5-3}} $\n",
    "\n",
    "$ y = 4 + 2 (x - 3) $\n",
    "\n",
    "$ y = 2_x - 2 $\n",
    "\n",
    "So if we want to know the height on the 4th day, we subsitue x with 4:\n",
    "\n",
    "$ y = 2 x 4 - 2 $\n",
    "\n",
    "$ y = 6 $\n",
    "\n",
    "\n",
    "| Day | Height |\n",
    "| --- | ------ |\n",
    "| 1 | 0 |\n",
    "| 3 | 4 |\n",
    "| 4 | 6 |\n",
    "| 5 | 8 |\n",
    "| 7 | 12 |\n",
    "| 9 | 16 | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd827094-a8ed-413c-9d97-b3287b71ee09",
   "metadata": {},
   "source": [
    "#### K neareast neighbors\n",
    "\n",
    "Lets take a look at a database where we are tracking cuts of wood for floor plans. Here using the K nearest neighbors would likely make a lot of sense.\n",
    "\n",
    "| Length | Width |\n",
    "| ------ | ----- |\n",
    "| 10 | 9 |\n",
    "| 11 | 20 |\n",
    "| 10 | 10 |\n",
    "| 12 | 15 |\n",
    "| 13 | 13 |\n",
    "| 10 |\n",
    "\n",
    "We are missing the width value for a cut with a length of 10, so we can go through our database and take all the cuts with lenth of 10 and avrage our their width, giving us a good idea as what this width of our missing value would be. \n",
    "\n",
    "| Length | Width |\n",
    "| ------ | ----- |\n",
    "| 10 | 9 |\n",
    "| 11 | 20 |\n",
    "| 10 | 10 |\n",
    "| 12 | 15 |\n",
    "| 13 | 13 |\n",
    "| 10 | 9.5 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b68fb-d49f-443b-a92a-9abcfa7b4473",
   "metadata": {},
   "source": [
    "### Invalid Data\n",
    "\n",
    "Data that does not meet the requirements needed for our analysis. A good example would be having numbers represented as as string. Lets look at those BTC values.\n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | \"103\" |\n",
    "| 12:03 | 100 |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "\n",
    "At 12:02 the value of 103 has been inputed as a string, when working with python for instance, we will not be able to preform and mathmatical operations on this value as python sees it as a word and not an integer. For this reason it is importand to validate all the data in our database to insure that our values or in the correct format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a210150-a09c-4292-bf05-da12c025419c",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "A value in a data set that is very different from the other values. That is, outliers are values unusually far from the middle. In most cases, outliers have influence on mean , but not on the median , or mode.\n",
    "\n",
    "Again lets take a look at out BTC value table. \n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | 103 |\n",
    "| 12:03 | 100 |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "| 12:59 | 101 |\n",
    "| 01:00 | 100 |\n",
    "| 01:01 | 1001 |\n",
    "| 01:02 | 103 |\n",
    "| 01:03 | 100 |\n",
    "| 01:04 | 100 |\n",
    "| etc. |  |\n",
    "| 01:59 | 101 |\n",
    "\n",
    "In this table we can see that at 1:01 we seem to have any outlier! 1000 is far above all the other values for BTC and it will therefore thorugh off our analysis when we start working with our data. We will need to remove this entry as it will greatly affect our analysis. \n",
    "\n",
    "| Time | BTC |\n",
    "| ---- | --- |\n",
    "| 12:00 | 100 |\n",
    "| 12:01 | 101 |\n",
    "| 12:02 | 103 |\n",
    "| 12:03 | 100 |\n",
    "| 12:04 | 100 |\n",
    "| etc. |  |\n",
    "| 12:59 | 101 |\n",
    "| 01:00 | 100 |\n",
    "| 01:02 | 103 |\n",
    "| 01:03 | 100 |\n",
    "| 01:04 | 100 |\n",
    "| etc. |  |\n",
    "| 01:59 | 101 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b16311-b7be-4683-a961-c310d6763082",
   "metadata": {},
   "source": [
    "## Non-parametric Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8414d-736c-447d-af6f-01cb4b631ef7",
   "metadata": {},
   "source": [
    "Data that does not fit a known or well-understood distribution is referred to as nonparametric data.\n",
    "\n",
    "Data could be non-parametric for many reasons, such as:\n",
    "\n",
    "- Data is not real-valued, but instead is ordinal, intervals, or some other form.\n",
    "- Data is real-valued but does not fit a well understood shape.\n",
    "- Data is almost parametric but contains outliers, multiple peaks, a shift, or some other feature.\n",
    "\n",
    "There are a suite of methods that we can use for nonparametric data called nonparametric statistical methods. In fact, most parametric methods have an equivalent nonparametric version.\n",
    "\n",
    "In general, the findings from nonparametric methods are less powerful than their parametric counterparts, namely because they must be generalized to work for all types of data. We can still use them for inference and make claims about findings and results, but they will not hold the same weight as similar claims with parametric methods. Information about the distribution is discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ae6a9-98a6-4aa7-9c63-3e28b0397243",
   "metadata": {},
   "source": [
    "### Ranking Data\n",
    "\n",
    "Before a nonparametric statistical method can be applied, the data must be converted into a rank format.\n",
    "\n",
    "As such, statistical methods that expect data in rank format are sometimes called rank statistics, such as rank correlation and rank statistical hypothesis tests.\n",
    "\n",
    "Ranking data is exactly as its name suggests. The procedure is as follows:\n",
    "\n",
    "- Sort all data in the sample in ascending order.\n",
    "- Assign an integer rank from 1 to N for each unique value in the data sample.\n",
    "\n",
    "We wont dive too much deeper into this concept as this does invole machine learning and some more advanced concepts, but do know that it exists and will be someting that will need to be delt with when working with real world data. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
